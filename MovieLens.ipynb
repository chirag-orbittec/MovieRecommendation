{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collaborative Filtering ALS Recommender System using Spark MLlib adapted from\n",
    "the Spark Summit 2014 Recommender System training example.\n",
    "\n",
    "Developed By: Pranav Masariya\n",
    "Supervisor: Dr. Magdalini Eirinaki\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.ml.recommendation import ALS as mlals\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "import math\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling spark session to register application\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Recom\") \\\n",
    "    .config(\"spark.recom.demo\", \"1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading and Parsing Dataset\n",
    "    Each line in the ratings dataset (ratings.csv) is formatted as:\n",
    "         userId,movieId,rating,timestamp\n",
    "    Each line in the movies (movies.csv) dataset is formatted as:\n",
    "        movieId,title,genres\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "# Load ratings\n",
    "ratings_df = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: int]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|   196|    242|     3|\n",
      "|   186|    302|     3|\n",
      "|    22|    377|     1|\n",
      "|   244|     51|     2|\n",
      "|   166|    346|     1|\n",
      "|   298|    474|     4|\n",
      "|   115|    265|     2|\n",
      "|   253|    465|     5|\n",
      "|   305|    451|     3|\n",
      "|     6|     86|     3|\n",
      "|    62|    257|     2|\n",
      "|   286|   1014|     5|\n",
      "|   200|    222|     5|\n",
      "|   210|     40|     3|\n",
      "|   224|     29|     3|\n",
      "|   303|    785|     3|\n",
      "|   122|    387|     5|\n",
      "|   194|    274|     2|\n",
      "|   291|   1042|     4|\n",
      "|   234|   1184|     2|\n",
      "|   119|    392|     4|\n",
      "|   167|    486|     4|\n",
      "|   299|    144|     4|\n",
      "|   291|    118|     2|\n",
      "|   308|      1|     4|\n",
      "|    95|    546|     2|\n",
      "|    38|     95|     5|\n",
      "|   102|    768|     2|\n",
      "|    63|    277|     4|\n",
      "|   160|    234|     5|\n",
      "+------+-------+------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For the simplicity of this tutorial\n",
    "    For each line in the ratings dataset, we create a tuple of (UserID, MovieID, Rating). \n",
    "    We drop the timestamp because we do not need it for this recommender.\n",
    "\"\"\"\n",
    "\n",
    "#ratings_df = ratings_df.drop('timestamp')\n",
    "ratings_df.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load movies\n",
    "movies_df = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"ml-latest-small/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For each line in the movies dataset, we create a tuple of (MovieID, Title). \n",
    "    We drop the genres because we do not use them for this recommender.\n",
    "\"\"\"\n",
    "movies_df = movies_df.drop('genres')\n",
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In order to determine the best ALS parameters, we will use the small dataset. \n",
    "We need first to split it into train, validation, and test datasets.\n",
    "\"\"\"\n",
    "(trainingData,validationData,testData) = ratings_df.randomSplit([0.6,0.2,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test and validation set. They should not have ratings\n",
    "\n",
    "validation_for_predict = validationData.select('userId','movieId')\n",
    "test_for_predict = testData.select('userId','movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spark MLlib library for Machine Learning provides a Collaborative Filtering implementation by \n",
    "using Alternating Least Squares. The implementation in MLlib has the following parameters:\n",
    "\n",
    "    1. numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).\n",
    "    2. rank is the number of latent factors in the model.\n",
    "    3. iterations is the number of iterations to run.\n",
    "    4. lambda specifies the regularization parameter in ALS.\n",
    "    5. implicitPrefs specifies whether to use the explicit \n",
    "        feedback ALS variant or one adapted for implicit feedback data.\n",
    "    6. alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline \n",
    "        confidence in preference observations.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "seed = 5 #Random seed for initial matrix factorization model. A value of None will use system time as the seed.\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1 #run for different lambdas - e.g. 0.01\n",
    "ranks = [4, 8, 12] #number of features\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.9477245381450695\n",
      "For rank 8 the RMSE is 0.9532198469578983\n",
      "For rank 12 the RMSE is 0.9526420573918778\n",
      "The best model was trained with rank 4\n"
     ]
    }
   ],
   "source": [
    "# Let us traing our dataset and check the best rank with lowest RMSE\n",
    "# predictAll method of the ALS takes only RDD format and hence we need to convert our dataframe into RDD\n",
    "# df.rdd will automatically converts Dataframe into RDD\n",
    "\n",
    "for rank in ranks:\n",
    "    model = ALS.train(trainingData, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict.rdd).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validationData.rdd.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) # RMSE Error\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print ('For rank %s the RMSE is %s' % (rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print ('The best model was trained with rank %s' % best_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spark will soon deprecate MLLIb package. \n",
    "They are focusing more on ML packages with standard machine learning implementation\n",
    "Let's see that package also\n",
    "\"\"\"\n",
    "als =  mlals(maxIter=iterations,rank=4,seed=seed,regParam=regularization_parameter, userCol=\"userId\", itemCol=\"movieId\",ratingCol=\"rating\")\n",
    "modelML = als.fit(trainingData)\n",
    "pred = modelML.transform(validationData)\n",
    "pred = pred.where(pred['prediction'] != 'NaN')\n",
    "    \n",
    "# Evaluate the model by computing RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(pred)\n",
    "\n",
    "print 'RMSE is %s' % rmse\n",
    "\n",
    "\"\"\"\n",
    "The best part is we do not have to worry about RDD any more with this library\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's take test dataset and get ratings\n",
    "predictions_test = model.predictAll(test_for_predict.rdd).map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((292, 320), 4.163789684707593),\n",
       " ((13, 320), 2.4530965672566305),\n",
       " ((118, 320), 4.9492797323585265)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## visualize preditions, here third element is predictions generated by ALS Model\n",
    "predictions_test.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's start recommending movies.\n",
    "I have written a method to call recommendations for a perticular user from test data\n",
    "\n",
    "TODO: You need to execute one more step before calling getRecommendations, \n",
    "      Think about that step. If you go through the seps below, you will realize it soon.\n",
    "\"\"\"\n",
    "def getRecommendations(user,testDf,trainDf,model):\n",
    "    # get all user and his/her rated movies\n",
    "    userDf = testDf.filter(testDf.userId == user)\n",
    "    # filter movies from main set which have not been rated by selected user\n",
    "    # and pass it to model we sreated above\n",
    "    mov = trainDf.select('movieId').subtract(userDf.select('movieId'))\n",
    "    \n",
    "    # Again we need to covert our dataframe into RDD\n",
    "    pred_rat = model.predictAll(mov.rdd.map(lambda x: (user, x[0]))).collect()\n",
    "    \n",
    "    # Get the top recommendations\n",
    "    recommendations = sorted(pred_rat, key=lambda x: x[2], reverse=True)[:50]\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies recommended for:336\n"
     ]
    }
   ],
   "source": [
    "# Assign user id for which we need recommendations\n",
    "user = 336\n",
    "\n",
    "# Call getRecommendations method\n",
    "derived_rec = getRecommendations(user,testData,trainingData,model)\n",
    "\n",
    "print (\"Movies recommended for:%d\" % user)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=336, product=1368, rating=5.1981050690456625),\n",
       " Rating(user=336, product=958, rating=4.814280433278696),\n",
       " Rating(user=336, product=272, rating=4.709120785820507),\n",
       " Rating(user=336, product=1282, rating=4.687403767642065),\n",
       " Rating(user=336, product=315, rating=4.654853148942708),\n",
       " Rating(user=336, product=64, rating=4.611159440477497),\n",
       " Rating(user=336, product=192, rating=4.57882490756566),\n",
       " Rating(user=336, product=316, rating=4.555875752573431),\n",
       " Rating(user=336, product=357, rating=4.534705183664028),\n",
       " Rating(user=336, product=1643, rating=4.524863260473367),\n",
       " Rating(user=336, product=127, rating=4.521642274576629),\n",
       " Rating(user=336, product=1639, rating=4.497326809163149),\n",
       " Rating(user=336, product=954, rating=4.4886930781352214),\n",
       " Rating(user=336, product=1512, rating=4.4623095886606015),\n",
       " Rating(user=336, product=318, rating=4.456360167609304),\n",
       " Rating(user=336, product=114, rating=4.454167268584019),\n",
       " Rating(user=336, product=302, rating=4.430053560990084),\n",
       " Rating(user=336, product=305, rating=4.425161143705811),\n",
       " Rating(user=336, product=1467, rating=4.416363451717364),\n",
       " Rating(user=336, product=896, rating=4.397850898171108),\n",
       " Rating(user=336, product=1388, rating=4.387526697639843),\n",
       " Rating(user=336, product=1315, rating=4.384466240049657),\n",
       " Rating(user=336, product=276, rating=4.383322984516472),\n",
       " Rating(user=336, product=1585, rating=4.3739456582065666),\n",
       " Rating(user=336, product=913, rating=4.3739456582065666),\n",
       " Rating(user=336, product=1650, rating=4.3739456582065666),\n",
       " Rating(user=336, product=1651, rating=4.3739456582065666),\n",
       " Rating(user=336, product=1636, rating=4.3739456582065666),\n",
       " Rating(user=336, product=1645, rating=4.3739456582065666),\n",
       " Rating(user=336, product=1242, rating=4.37382417707793),\n",
       " Rating(user=336, product=107, rating=4.373213282086353),\n",
       " Rating(user=336, product=56, rating=4.3665029512565905),\n",
       " Rating(user=336, product=1449, rating=4.36543610928881),\n",
       " Rating(user=336, product=237, rating=4.320411397337249),\n",
       " Rating(user=336, product=865, rating=4.31937872175277),\n",
       " Rating(user=336, product=187, rating=4.308434671936066),\n",
       " Rating(user=336, product=296, rating=4.29663054702281),\n",
       " Rating(user=336, product=1134, rating=4.2961606762645435),\n",
       " Rating(user=336, product=197, rating=4.287157295449994),\n",
       " Rating(user=336, product=1262, rating=4.272171944685728),\n",
       " Rating(user=336, product=1195, rating=4.262051113493577),\n",
       " Rating(user=336, product=1240, rating=4.249242490201347),\n",
       " Rating(user=336, product=285, rating=4.247345649641053),\n",
       " Rating(user=336, product=182, rating=4.240773532713259),\n",
       " Rating(user=336, product=98, rating=4.2370073277812565),\n",
       " Rating(user=336, product=483, rating=4.2356325332470846),\n",
       " Rating(user=336, product=1524, rating=4.221051264682355),\n",
       " Rating(user=336, product=11, rating=4.213905140896904),\n",
       " Rating(user=336, product=216, rating=4.21276514756439),\n",
       " Rating(user=336, product=1302, rating=4.207321459006317)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the result\n",
    "# TODO: we can convert derived_rec into a dataframe to present it properly\n",
    "for i in xrange(len(derived_rec)):\n",
    "    print i+1\n",
    "    movies_df.filter(movies_df.movieId==derived_rec[i][1]).select('title').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
